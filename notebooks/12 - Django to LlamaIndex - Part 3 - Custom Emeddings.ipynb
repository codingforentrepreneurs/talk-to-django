{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b5f7338-de48-48b2-a2ce-956150fabd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import setup\n",
    "\n",
    "setup.init_django()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e3a536a-02b6-4243-97ba-751815314c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import config\n",
    "from blog.models import BlogPost\n",
    "from blog import services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b66c90da-a020-4ab6-8f77-7b2797d17e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# qs = BlogPost.objects.filter(can_delete=True)\n",
    "# qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7436777e-4817-4f18-84ec-1e6975000e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llama-index sqlalchemy llama-index-vector-stores-postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9f2d465-9e22-40ff-b565-3a06e4c00f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3f4d9bd-d4d2-41ab-b024-d8c8654f63c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_MODEL = config(\"LLM_MODEL\", default=\"gpt-4o\") # not in use use\n",
    "EMEDDING_LENGTH = config(\"EMEDDING_LENGTH\", default=1536, cast=int)\n",
    "EMEDDING_MODEL =config(\"EMEDDING_MODEL\", default=\"text-embedding-3-small\")\n",
    "OPENAI_API_KEY = config(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = OpenAI(model=LLM_MODEL, api_key=OPENAI_API_KEY)\n",
    "embed_model = OpenAIEmbedding(model=EMEDDING_MODEL, api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "50981128-db62-4a5c-9756-5c39b2da129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class MyOpenAIEmbedding(OpenAIEmbedding):\n",
    "    \n",
    "    def _get_query_embedding(self, query: str) -> List[float]:\n",
    "        \"\"\"Get query embedding.\"\"\"\n",
    "        print('my query', query) \n",
    "        # obj, created = Query.objects.get_or_create(query=query)\n",
    "        # obj.get_query_embedding()\n",
    "        return super()._get_query_embedding(query)\n",
    "\n",
    "    def _get_text_embedding(self, text: str) -> List[float]:\n",
    "        \"\"\"Get text embedding.\"\"\"\n",
    "        print(\"texts\", text)\n",
    "        return super()._get_text_embedding(text)\n",
    "\n",
    "    def _get_text_embeddings(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Get text embeddings.\n",
    "\n",
    "        By default, this is a wrapper around _get_text_embedding.\n",
    "        Can be overridden for batch queries.\n",
    "        \"\"\"\n",
    "        print(\"texts\", texts)\n",
    "        return super()._get_text_embeddings(texts)\n",
    "        \n",
    "embed_model = MyOpenAIEmbedding(model=EMEDDING_MODEL, api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cd88f24c-5b04-46ec-b431-eafbbcedad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5db2ae42-5719-4213-8336-91319d9d013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_db_name = \"vector_db\"\n",
    "vector_db_table_name = \"blogpost\" # -> data_blogpost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "466f8d1d-ee71-4c46-96ba-823ccaeb4bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATABASE_URL = config(\"DATABASE_URL_POOL\")\n",
    "if DATABASE_URL.startswith(\"postgres://\"):\n",
    "    DATABASE_URL = DATABASE_URL.replace(\"postgres://\", \"postgresql://\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7571ae4f-9d31-40f9-935a-c44eb8c1bb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new database\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "engine = create_engine(DATABASE_URL, isolation_level=\"AUTOCOMMIT\")\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text(\"SELECT 1 FROM pg_database WHERE datname = :db_name\"), {\"db_name\": vector_db_name})\n",
    "    db_exists = result.scalar() == 1\n",
    "    if not db_exists:\n",
    "        session.execute(text('CREATE EXTENSION IF NOT EXISTS vector'))\n",
    "        connection.execute(text(f\"CREATE DATABASE {vector_db_name}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2aaea3c8-d241-41c7-aa8a-ade68da9fda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import make_url\n",
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "\n",
    "url = make_url(DATABASE_URL)\n",
    "vector_store = PGVectorStore.from_params(\n",
    "    database=vector_db_name,\n",
    "    host=url.host,\n",
    "    password=url.password,\n",
    "    port=url.port or 5432,\n",
    "    user=url.username,\n",
    "    table_name=vector_db_table_name,\n",
    "    embed_dim=EMEDDING_LENGTH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "69d03215-8be1-4c37-87a9-8e9d2adb5d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "index = VectorStoreIndex.from_vector_store(vector_store, storage_context=storage_context)\n",
    "query_engine = index.as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4da322-844c-4d33-b389-c2af636a8c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dcc9e537-494b-4ef7-94ad-ba1460341e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "docs = []\n",
    "qs = BlogPost.objects.filter(can_delete=True)\n",
    "for obj in qs:\n",
    "    docs.append(\n",
    "        Document(\n",
    "            text=f\"{obj.get_embedding_text_raw()}\",\n",
    "            doc_id=str(obj.id),\n",
    "            embedding=obj.embedding.tolist(),\n",
    "            metadata = {\n",
    "                \"pk\": obj.pk,\n",
    "                \"title\": obj.title\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "# docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5890e396-f2f0-456e-8b12-48b8e06a7c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    index.delete_ref_doc(f\"{doc.id_}\", delete_from_docstore=True)\n",
    "    index.insert(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "130ead94-e6a6-4566-b673-c185b8f9b7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my query The dog jumped\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"The dog jumped\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fff374aa-4331-4f48-96eb-cb8c0cb76cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pk 34\n",
      "title Blog Post 1\n",
      "pk 35\n",
      "title Blog Post 2\n"
     ]
    }
   ],
   "source": [
    "for k in response.metadata.keys():\n",
    "    for subk, v in response.metadata[k].items():\n",
    "        print(subk, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dee1dd1a-1605-43ad-8d88-09c8a311082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "port = url.port or 5432\n",
    "db_url = f\"postgresql://{url.username}:{url.password}@{url.host}:{port}/{vector_db_name}\"\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "with engine.connect() as connection:\n",
    "    # Define the SQL query to select only the id and embedding columns\n",
    "    query = text(f\"SELECT * FROM data_{vector_db_table_name}\")\n",
    "    query = text(f\"SELECT metadata_, embedding FROM data_{vector_db_table_name}\")\n",
    "    \n",
    "    # Execute the query\n",
    "    result = connection.execute(query)\n",
    "    \n",
    "    # Fetch all rows\n",
    "    rows = result.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "51a8d6d2-aafe-41fa-8991-fbb6d63c8a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_metrics(v1, v2):\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    magnitude1 = np.linalg.norm(v1)\n",
    "    magnitude2 = np.linalg.norm(v2)\n",
    "    cosine_similarity = dot_product / (magnitude1 * magnitude2)\n",
    "    cosine_distance = 1 - cosine_similarity\n",
    "    return int(cosine_similarity* 100), int(cosine_distance * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd1b03b6-64e6-414e-a192-32a4af3a2a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 0)\n",
      "(100, 0)\n",
      "(100, 0)\n",
      "(100, 0)\n"
     ]
    }
   ],
   "source": [
    "for row in rows:\n",
    "    metadata_, embedding = row[0], row[1]\n",
    "    # print(metadata_)\n",
    "    blog_post_pk = metadata_.get(\"pk\")\n",
    "    obj = BlogPost.objects.get(pk=blog_post_pk)\n",
    "    embedding_array = np.array(embedding.strip('[]').split(','), dtype=float)\n",
    "    obj_embedding_array = np.array(obj.embedding, dtype=float)\n",
    "    print(calculate_cosine_metrics(embedding_array.shape, obj_embedding_array.shape))\n",
    "    # print(obj.embedding, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf34ef2a-c398-40bd-9dbd-89c9ca8cada9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
